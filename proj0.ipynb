{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# codigo para pre-filtar imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar librerias de os, opencv, numpy y matplotlib\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#se pretende llamar el video, obtener de este solo 10 frames por segundo. \n",
    "#cada frame convertirlo a formato gray, hsv y Lab.\n",
    "#aplicar una limiarizacion y detectar bordes para identificar burbuas y partes de material.\n",
    "\n",
    "#create the folders where the results will be\n",
    "#crear carpetas (dentro de documentos) donde van a estar los resultados\n",
    "os.chdir('/home/jorge/Documents')\n",
    "os.mkdir('underwater_welding_arc_bubble')\n",
    "os.chdir('/home/jorge/Documents/underwater_welding_arc_bubble')\n",
    "os.mkdir('1_ori_10fxs')\n",
    "os.mkdir('2_gray')\n",
    "os.mkdir('3_hsv')\n",
    "os.mkdir('4_Lab')\n",
    "os.mkdir('5_Lim_adapt_mean')\n",
    "os.mkdir('6_Lim_adapt_gaus')\n",
    "os.mkdir('7_otsu')\n",
    "os.mkdir('8_bin_otsu')\n",
    "os.mkdir('9_canny')\n",
    "os.mkdir('10_bin_canny')\n",
    "os.mkdir('11_equ_adapt') #ecualizacion adaptativa al gray\n",
    "os.mkdir('12_bin_equ_adapt') # binarizacion y luego ecualizacion adaptativa al gray\n",
    "os.mkdir('13_adp_mean_cla1') # limiarizacion adaptativa media de la ecualizacion adaptativa al gray (#11)\n",
    "os.mkdir('14_adp_mean_cla2') # limiarizacion adaptativa media de la binarizacion y luego ecualizacion adaptativa al gray (#12)\n",
    "os.mkdir('15_adp_mean_#5') # ecualizacion adaptativa de limiarizacion adaptativa media (#5)\n",
    "\n",
    "\n",
    "# leer el video desde la ubicacion del archivo (video esta en formato .MP4)\n",
    "cap = cv2.VideoCapture('/home/jorge/Documents/bRASIL/investigación/Videos e Sinais Douglas TG/MP4/5.mp4')\n",
    "\n",
    "# Check if video opened successfully\n",
    "# asegurarse de que el video se abra satisfactoriamente\n",
    "if (cap.isOpened() == False): \n",
    "    print(\"error al abrir el video\")\n",
    "    print(\"Unable to read video feed\")\n",
    "\n",
    "\n",
    "# inicializar contadores\n",
    "i=0\n",
    "j=0\n",
    "\n",
    "while(True):\n",
    "    \n",
    "    # Capture frame-by-frame\n",
    "    # Capturar frame por frame\n",
    "    ret, frame = cap.read()\n",
    "        \n",
    "    # Convert each frame to grayscale, hsv and Lab\n",
    "    # Convertir cada frame a formato gray, hsv y Lab\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV) \n",
    "    Lab = cv2.cvtColor(frame, cv2.COLOR_BGR2Lab)\n",
    "\n",
    "    # Apply Canny Edge Detector, adaptiveThreshold mean and adaptiveThreshold gaussian\n",
    "    # Aplicar Canny para deteccion de bordes, \n",
    "    #limiarizacion adaptativa media y limiarizacion adaptativa media   \n",
    "    adp_mean = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C,     \\\n",
    "                                 cv2.THRESH_BINARY, 11, 2);  \n",
    "    adp_gau = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \\\n",
    "                                 cv2.THRESH_BINARY, 11, 2);\n",
    "    ret,otsu = cv2.threshold(gray, 0, 255, cv2.THRESH_OTSU)\n",
    "    bin2,otsu1 = cv2.threshold(otsu, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    canny = cv2.Canny(frame,100,200)\n",
    "    bin2,canny1 = cv2.threshold(canny, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    clahe = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(8,8))\n",
    "    cla1 = clahe.apply(gray)\n",
    "    \n",
    "    limiar, imgLimiar = cv2.threshold(gray, 200, 255, cv2.THRESH_TOZERO_INV)\n",
    "    \n",
    "    clahe2 = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(8,8))\n",
    "    cla2 = clahe2.apply(imgLimiar)\n",
    "    \n",
    "    adp_mean_cla1 = cv2.adaptiveThreshold(cla1, 255, cv2.ADAPTIVE_THRESH_MEAN_C,     \\\n",
    "                                 cv2.THRESH_BINARY, 11, 2); \n",
    "    adp_mean_cla2 = cv2.adaptiveThreshold(cla2, 255, cv2.ADAPTIVE_THRESH_MEAN_C,     \\\n",
    "                                 cv2.THRESH_BINARY, 11, 2); \n",
    "    \n",
    "    clahe3 = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "    cla3 = clahe3.apply(adp_mean)\n",
    "        \n",
    "    # Display the resulting frames in color, gayscale, hsv, Lab, canny, adp_mean y adp_gau formats\n",
    "    # imprimir el resultado de cada frame a formato original, gray, hsv, Lab, \n",
    "    #canny, adp_mean y adp_gau\n",
    "    \n",
    "    #cv2.namedWindow(\"frame_color\")\n",
    "    #cv2.imshow(\"frame_color\",frame)\n",
    "    \n",
    "    #cv2.namedWindow(\"frame_gray\")\n",
    "    #cv2.imshow(\"frame_gray\",gray)\n",
    "    \n",
    "    #cv2.namedWindow(\"frame_hsv\")\n",
    "    #cv2.imshow(\"frame_hsv\",hsv)\n",
    "    \n",
    "    #cv2.namedWindow(\"frame_Lab\")\n",
    "    #cv2.imshow(\"frame_Lab\",Lab)\n",
    "    \n",
    "    #cv2.namedWindow(\"frame_canny\")\n",
    "    #cv2.imshow(\"frame_canny\",canny)\n",
    "    \n",
    "    #cv2.namedWindow(\"frame_adp_mean\")\n",
    "    #cv2.imshow(\"frame_adp_mean\",adp_mean)\n",
    "    \n",
    "    #cv2.namedWindow(\"frame_adp_gau\")\n",
    "    #cv2.imshow(\"frame_adp_gau\",adp_gau)\n",
    "    \n",
    "    # Save images every 3 frames captured by the video .tif format\n",
    "    #(it is needed 10frames/s and the video has 30frames/s)\n",
    "    #guardar imagenes cada 3 frames, formato .tif\n",
    "    #(necesitamos 10fr/s y el video tiene 30fr/s)\n",
    "    if i == (j*3):\n",
    "        cv2.imwrite('/home/jorge/Documents/underwater_welding_arc_bubble/1_ori_10fxs/image'+str(j)+'.tif', frame)\n",
    "        cv2.imwrite('/home/jorge/Documents/underwater_welding_arc_bubble/2_gray/image'+str(j)+'.tif', gray)\n",
    "        cv2.imwrite('/home/jorge/Documents/underwater_welding_arc_bubble/3_hsv/image'+str(j)+'.tif', hsv)\n",
    "        cv2.imwrite('/home/jorge/Documents/underwater_welding_arc_bubble/4_Lab/image'+str(j)+'.tif', Lab)   \n",
    "        cv2.imwrite('/home/jorge/Documents/underwater_welding_arc_bubble/5_Lim_adapt_mean/image'+str(j)+'.tif', adp_mean)\n",
    "        cv2.imwrite('/home/jorge/Documents/underwater_welding_arc_bubble/6_Lim_adapt_mean/image'+str(j)+'.tif', adp_gau)\n",
    "        cv2.imwrite('/home/jorge/Documents/underwater_welding_arc_bubble/7_otsu/image'+str(j)+'.tif', otsu)\n",
    "        cv2.imwrite('/home/jorge/Documents/underwater_welding_arc_bubble/8_bin_otsu/image'+str(j)+'.tif', otsu1)\n",
    "        cv2.imwrite('/home/jorge/Documents/underwater_welding_arc_bubble/9_canny/image'+str(j)+'.tif', canny)\n",
    "        cv2.imwrite('/home/jorge/Documents/underwater_welding_arc_bubble/10_bin_canny/image'+str(j)+'.tif', canny1)\n",
    "        cv2.imwrite('/home/jorge/Documents/underwater_welding_arc_bubble/11_equ_adapt/image'+str(j)+'.tif', cla1)\n",
    "        cv2.imwrite('/home/jorge/Documents/underwater_welding_arc_bubble/12_bin_equ_adapt/image'+str(j)+'.tif', cla2)\n",
    "        cv2.imwrite('/home/jorge/Documents/underwater_welding_arc_bubble/13_adp_mean_cla1/image'+str(j)+'.tif', adp_mean_cla1)\n",
    "        cv2.imwrite('/home/jorge/Documents/underwater_welding_arc_bubble/14_adp_mean_cla2/image'+str(j)+'.tif', adp_mean_cla2)\n",
    "        cv2.imwrite('/home/jorge/Documents/underwater_welding_arc_bubble/15_adp_mean_#5/image'+str(j)+'.tif', cla3)\n",
    "        j += 1\n",
    "        \n",
    "    # Press \"q\" to quit\n",
    "    # Presione \"q\" para interrumpir\n",
    "    #if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        #break\n",
    "    i += 1\n",
    "# When everything done, release the capture and destroy all windows\n",
    "# Cuando haya terminado, entregar el video y destruir todas las carpetas \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "#Uma vez salvadas as imagens na pasta especificada anteriormente, \n",
    "as imagens podem ser mostradas da seguinte forma:\n",
    "# Show images contained in the folder\n",
    "\n",
    "\n",
    "import glob\n",
    "import matplotlib.image as mpimg\n",
    "img1w = glob.glob('Images_ponto_1/image*.tif')\n",
    "for x in range(len(img1w)):\n",
    "    img11 = mpimg.imread('Images_ponto_1/image%d.tif' % (x))\n",
    "    plt.title('image%d.tif' % (x), size=16)\n",
    "    plt.imshow(img11, cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hecha como borrador\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "cap = cv2.VideoCapture('/home/jorge/Documents/bRASIL/investigación/Videos e Sinais Douglas TG/MP4/5.mp4')\n",
    "if (cap.isOpened() == False): \n",
    "    print(\"error al abrir el video\")\n",
    "    print(\"Unable to read video feed\")\n",
    "i=0\n",
    "j=0\n",
    "while(True):        \n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV) \n",
    "    Lab = cv2.cvtColor(frame, cv2.COLOR_BGR2Lab)\n",
    "    canny = cv2.Canny(frame,100,200)\n",
    "    adp_mean = cv2.adaptiveThreshold(frame, 255, cv2.ADAPTIVE_THRESH_MEAN_C,     \\\n",
    "                                 cv2.THRESH_BINARY, 11, 2);  \n",
    "    adp_gau = cv2.adaptiveThreshold(frame, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \\\n",
    "                                 cv2.THRESH_BINARY, 11, 2);\n",
    "    if i == (j*3):\n",
    "        cv2.imwrite('/home/jorge/test_gray/image'+str(j)+'.tif', gray)\n",
    "        cv2.imwrite('/home/jorge/test_hsv/image'+str(j)+'.tif', hsv)\n",
    "        cv2.imwrite('/home/jorge/test_Lab/image'+str(j)+'.tif', Lab)\n",
    "        cv2.imwrite('/home/jorge/test_canny/image'+str(j)+'.tif', edges)\n",
    "        cv2.imwrite('/home/jorge/test_adp_mean/image'+str(j)+'.tif', adp_mean)\n",
    "        cv2.imwrite('/home/jorge/test_adp_gau/image'+str(j)+'.tif', adp_gau)       \n",
    "        j += 1\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    i += 1\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#esta se usara para ecualizacion del histograma\n",
    "\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "kernel_size = 7\n",
    "scale = 1\n",
    "delta = 0\n",
    "\n",
    "img1w = glob.glob('/home/jorge/graygray/*.tif')\n",
    "for x in range(len(img1w)):\n",
    "    img11 = mpimg.imread('/home/jorge/graygray/image%d.tif' % (x))\n",
    "    #equ = cv2.equalizeHist(img11)\n",
    "    #plt.title('imaget%d.tif' % (x), size=16)\n",
    "    #cv2.imshow('hhh',img11)\n",
    "    blur = cv2.bilateralFilter(img11,9,75,75)\n",
    "    limiar, imgLimiar = cv2.threshold(blur, 180, 255, cv2.THRESH_TOZERO_INV)\n",
    "    clahe3 = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(80,80))\n",
    "    clah3 = clahe3.apply(imgLimiar)\n",
    "    #Lapla = cv2.Laplacian(clah3,cv2.CV_64F)\n",
    "    \n",
    "    blur = cv2.GaussianBlur( clah3,(3,3), 0)\n",
    "    lap = cv2.Laplacian( blur, cv2.CV_16S, kernel_size, scale, delta)\n",
    "    \n",
    "    res = cv2.convertScaleAbs(lap)\n",
    "    \n",
    "    img_res = img11 - res\n",
    "    \n",
    "    #gray = cv2.cvtColor(img_res, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    limiar, imgLimiar = cv2.threshold(img_res, 15, 255, cv2.THRESH_TOZERO)\n",
    "    #limiar2, imgLimiar2 = cv2.threshold(imgLimiar, 60, 255, cv2.THRESH_TOZERO)\n",
    "\n",
    "    \n",
    "    #plt.imshow(equ,cmap = 'gray')\n",
    "    #plt.imsave(\"/home/jorge/graygray/imaget%d.tif\" % (x), equ)\n",
    "    #res = np.hstack((img11,equ)) #stacking images side-by-side\n",
    "    cv2.imwrite('final_%d.png' % (x),imgLimiar)\n",
    "    cv2.imwrite('lapla7_%d.png' % (x),lap)\n",
    "    cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacer ecualizacion del histograma adaptativa a una imagen\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('/home/jorge/Downloads/mario.png',0)\n",
    "\n",
    "# create a CLAHE object (Arguments are optional).\n",
    "clahe2 = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(100,100))\n",
    "cl1 = clahe2.apply(img)\n",
    "\n",
    "cv2.imwrite('cma0.jpg',cl1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#esta se usara para cambiar los bits de v del hsv a toda una carpeta\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "img1 = glob.glob('/home/jorge/graygray/*.tif')\n",
    "for x in range(len(img1)):\n",
    "    img2 = mpimg.imread('/home/jorge/graygray/image%d.tif' % (x))\n",
    "    #equ = cv2.equalizeHist(img2)\n",
    "    #clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    #clah = clahe.apply(img2)\n",
    "    #plt.title('imaget%d.tif' % (x), size=16)\n",
    "    #plt.imshow(img2, cmap='gray')\n",
    "    imgray2brg = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n",
    "    hsv_img = cv2.cvtColor(imgray2brg, cv2.COLOR_BGR2HSV)\n",
    "    hsv_img[:,:,2]=0\n",
    "    cv2.imwrite('/home/jorge/res_hsv/hv_%d.png' % (x),hsv_img)\n",
    "    #plt.imshow(equ,cmap = 'gray')\n",
    "    #plt.imsave(\"/home/jorge/graygray/imaget%d.tif\" % (x), equ)\n",
    "    #res = np.hstack((img11,equ)) #stacking images side-by-side\n",
    "    \n",
    "    \n",
    "    #cv2.imwrite('/home/jorge/res_hsv/res%d.png' % (x),equ)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#esta se usara para cambiar los bits de v del hsv (una sola imagen) \n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img2 = cv2.imread('/home/jorge/test_hsv/image34.tif')\n",
    "\n",
    "img2[:,:,1]=0\n",
    "img2[:,:,0]=0\n",
    "\n",
    "hsv_bgr = cv2.cvtColor(img2, cv2.COLOR_HSV2BGR)\n",
    "gray = cv2.cvtColor(hsv_bgr, cv2.COLOR_BGR2GRAY)\n",
    "gray[gray>160] = 100\n",
    "cv2.imshow('dire',gray);\n",
    "\n",
    "#limiar2, imgLimiar2 = cv2.threshold(gray, 120, 255, cv2.THRESH_TRUNC)\n",
    "#cv2.imshow('jah',imgLimiar2);\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "#cv2.imwrite('mauricio.png',img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#esta se usara limitar los pixeles de brillo \n",
    "#para aplicar ecualizacion normal y clahe a diferentes parametros\n",
    "\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img1 = glob.glob('/home/jorge/graygray/*.tif')\n",
    "for x in range(len(img1)):\n",
    "    img2 = mpimg.imread('/home/jorge/graygray/image%d.tif' % (x))\n",
    "    \n",
    "    limiar, imgLimiar = cv2.threshold(img2, 200, 255, cv2.THRESH_TOZERO_INV)\n",
    "    #cv2.imwrite('bina2.png',imgLimiar)\n",
    "    limiar2, imgLimiar2 = cv2.threshold(img2, 120, 255, cv2.THRESH_TRUNC)\n",
    "\n",
    "    cv2.imwrite('/home/jorge/res_hsv/imglimi_%d.tif' % (x),imgLimiar)\n",
    "    cv2.imwrite('/home/jorge/res_hsv/imglimit_%d.tif' % (x),imgLimiar2)\n",
    "    \n",
    "\"\"\"   \n",
    "    equ = cv2.equalizeHist(imgLimiar)\n",
    "    \n",
    "    clahe1 = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    clah1 = clahe1.apply(imgLimiar)\n",
    "    \n",
    "    clahe2 = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(80,80))\n",
    "    clah2 = clahe2.apply(imgLimiar)\n",
    "    \n",
    "    clahe3 = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(80,80))\n",
    "    clah3 = clahe3.apply(imgLimiar)\n",
    "    \n",
    "    clahe4 = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(100,100))\n",
    "    clah4 = clahe4.apply(imgLimiar)\n",
    "    \n",
    "    clahe5 = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(100,100))\n",
    "    clah5 = clahe5.apply(imgLimiar)\n",
    "\"\"\" \n",
    "\"\"\" \n",
    "    cv2.imwrite('/home/jorge/ecu/equ_lim%d.png' % (x),equ)   \n",
    "    cv2.imwrite('/home/jorge/clah28x8/clah_2.0_8x8_%d.png' % (x),clah1)\n",
    "    cv2.imwrite('/home/jorge/clah380x80/clah_3.0_80x80_%d.png' % (x),clah2)\n",
    "    cv2.imwrite('/home/jorge/clah480x80/clah_4.0_80x80_%d.png' % (x),clah3)\n",
    "    cv2.imwrite('/home/jorge/clah3100x100/clah_3.0_100x100_%d.png' % (x),clah4)\n",
    "    cv2.imwrite('/home/jorge/clah4100x100/clah_4.0_100x100_%d.png' % (x),clah5)\n",
    "\"\"\" \n",
    "\n",
    "    #res = np.hstack((img11,equ)) #stacking images side-by-side\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aprendiendo  laplace\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "#img = np.zeros((3,3), dtype=np.uint8)\n",
    "#print(img.shape)\n",
    "#print(img)\n",
    "#print('hey')\n",
    "#img_3 = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "#print(img_3)\n",
    "#img_3.shape\n",
    "\n",
    "\n",
    "kernel_size = 7\n",
    "scale = 1\n",
    "delta = 0\n",
    "\n",
    "src = cv2.imread('clah_0.png') \n",
    "dos = cv2.imread('/home/jorge/graygray/image0.tif')\n",
    "\n",
    "#gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "blur = cv2.GaussianBlur( src,(3,3), 0);\n",
    "\n",
    "lap = cv2.Laplacian( blur, cv2.CV_16S, kernel_size, scale, delta);\n",
    "\n",
    "res = cv2.convertScaleAbs(lap);\n",
    "\n",
    "img_res = src - res\n",
    "\n",
    "gray = cv2.cvtColor(img_res, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "limiar, imgLimiar = cv2.threshold(gray, 20, 255, cv2.THRESH_TOZERO)\n",
    "limiar2, imgLimiar2 = cv2.threshold(imgLimiar, 40, 255, cv2.THRESH_TOZERO_INV)\n",
    "\n",
    "#aa = cv2.inRange(img_res, 20, 60, 0);\n",
    "\n",
    "cv2.imshow( 'todo',imgLimiar );\n",
    "cv2.imshow( 'dire',imgLimiar2 );\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pruebas con laplace\n",
    "\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "kernel_size = 3\n",
    "scale = 1\n",
    "delta = 3\n",
    "\n",
    "img1w = glob.glob('/home/jorge/graygray/*.tif')\n",
    "for x in range(len(img1w)):\n",
    "    img11 = mpimg.imread('/home/jorge/graygray/image%d.tif' % (x))\n",
    "    #equ = cv2.equalizeHist(img11)\n",
    "    #plt.title('imaget%d.tif' % (x), size=16)\n",
    "    #cv2.imshow('hhh',img11)\n",
    "    blur = cv2.bilateralFilter(img11,9,75,75)\n",
    "    limiar, imgLimiar = cv2.threshold(blur, 180, 255, cv2.THRESH_TOZERO_INV)\n",
    "    clahe3 = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(80,80))\n",
    "    clah3 = clahe3.apply(imgLimiar)\n",
    "    \n",
    "    \n",
    "    #Lapla = cv2.Laplacian(clah3,cv2.CV_64F)\n",
    "    lap = cv2.Laplacian(clah3, cv2.CV_8U, kernel_size, scale, delta, cv2.BORDER_REPLICATE)\n",
    "    resu = clah3 + lap\n",
    "    \n",
    "    #blur = cv2.GaussianBlur( clah3,(3,3), 0)\n",
    "    #lap = cv2.Laplacian( blur, cv2.CV_16S, kernel_size, scale, delta)\n",
    "    \n",
    "    #res = cv2.convertScaleAbs(lap)\n",
    "    \n",
    "    #img_res = img11 - res\n",
    "    \n",
    "    #gray = cv2.cvtColor(img_res, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    limiar2, imgLimiar2 = cv2.threshold(resu, 15, 255, cv2.THRESH_TOZERO)\n",
    "    limiar3, imgLimiar3 = cv2.threshold(imgLimiar2, 60, 255, cv2.THRESH_TOZERO)\n",
    "\n",
    "    \n",
    "    #plt.imshow(equ,cmap = 'gray')\n",
    "    #plt.imsave(\"/home/jorge/graygray/imaget%d.tif\" % (x), equ)\n",
    "    #res = np.hstack((img11,equ)) #stacking images side-by-side\n",
    "    cv2.imwrite('lap_%d.png' % (x),lap)\n",
    "    cv2.imwrite('final_%d.png' % (x),imgLimiar3)\n",
    "    #cv2.imwrite('lapla7_%d.png' % (x),lap)\n",
    "    cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# laplace con ing. Brayan\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "src = cv2.imread('/home/jorge/Documents/underwater_welding_arc_bubble/1_ori_10fxs/image34.tif')\n",
    "\n",
    "gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "blur = cv2.bilateralFilter(gray,5,45,45)\n",
    "limiar, imgLimiar = cv2.threshold(blur, 10, 255, cv2.THRESH_TOZERO)\n",
    "clahe3 = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(145,145))\n",
    "clah3 = clahe3.apply(imgLimiar)\n",
    "#limiar, imgLimiar = cv2.threshold(clah3, 230, 255, cv2.THRESH_TOZERO_INV)\n",
    "\n",
    "\n",
    "\n",
    "#You can try more different parameters\n",
    "a=cv2.Laplacian(clah3, cv2.CV_8U,1,1, 3, cv2.BORDER_DEFAULT);\n",
    "    \n",
    "#res = cv2.convertScaleAbs(a)\n",
    "    \n",
    "#img_res = gray - res\n",
    "res = cv2.addWeighted(clah3,1.5,a,-0.5,0)\n",
    "\n",
    "#res= clah3 - a\n",
    "\n",
    "limiar2, imgLimiar2 = cv2.threshold(res, 90, 200, cv2.THRESH_TOZERO)# pixeles mayores a 20 =n\n",
    "\n",
    "\n",
    "#limiar3, imgLimiar3 = cv2.threshold(imgLimiar2, 10, 200, cv2.THRESH_BINARY_INV)# pixeles mayores a 20 =n\n",
    "\n",
    "\n",
    "cv2.imshow('clah3', clah3);\n",
    "cv2.imshow('blur', blur);\n",
    "cv2.imshow('limiar1', imgLimiar);\n",
    "cv2.imshow('limiar2', imgLimiar2);\n",
    "#cv2.imshow('limiar3', imgLimiar3);\n",
    "cv2.imshow('laplaciano', a);\n",
    "cv2.imshow('resta', res);\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmeans a una imagen\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('/home/jorge/Documents/underwater_welding_arc_bubble/1_ori_10fxs/image34.tif')\n",
    "\n",
    "# convert to np.float32\n",
    "Z = np.float32(img)\n",
    "\n",
    "# define criteria, number of clusters(K) and apply kmeans()\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "K = 3\n",
    "ret,label,center=cv2.kmeans(Z,K,None,criteria,10,cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "# Now convert back into uint8, and make original image\n",
    "center = np.uint8(center)\n",
    "res = center[label.flatten()]\n",
    "\n",
    "res3 = res.reshape((img.shape))\n",
    "\n",
    "\n",
    "cv2.imshow('imagen',res3)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intentando hacer knn en una imagen\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('/home/jorge/Documents/underwater_welding_arc_bubble/1_ori_10fxs/image32.tif')\n",
    "cv2.imshow('imagen',img)\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Now we split the image to 5000 cells, each 20x20 size\n",
    "cells = [np.hsplit(row,100) for row in np.vsplit(gray,50)]\n",
    "\n",
    "# Make it into a Numpy array. It size will be (50,100,20,20)\n",
    "x = np.array(cells)\n",
    "\n",
    "# Now we prepare train_data and test_data.\n",
    "train = x[:,:50].reshape(-1,400).astype(np.float32) # Size = (2500,400)\n",
    "test = x[:,50:100].reshape(-1,400).astype(np.float32) # Size = (2500,400)\n",
    "\n",
    "# Create labels for train and test data\n",
    "k = np.arange(10)\n",
    "train_labels = np.repeat(k,250)[:,np.newaxis]\n",
    "test_labels = train_labels.copy()\n",
    "\n",
    "# Initiate kNN, train the data, then test it with test data for k=1\n",
    "knn = cv2.KNearest()\n",
    "knn.train(train,train_labels)\n",
    "ret,result,neighbours,dist = knn.find_nearest(test,k=5)\n",
    "\n",
    "# Now we check the accuracy of classification\n",
    "# For that, compare the result with test_labels and check which are wrong\n",
    "matches = result==test_labels\n",
    "correct = np.count_nonzero(matches)\n",
    "accuracy = correct*100.0/result.size\n",
    "print (accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reducir brillo\n",
    "\n",
    "#import the necessary packages\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread('clah_0.png')\n",
    "\n",
    "def adjust_gamma(image, gamma=1.0):\n",
    "    # build a lookup table mapping the pixel values [0, 255] to\n",
    "    # their adjusted gamma values\n",
    "    invGamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** invGamma) * 255\n",
    "        for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "\n",
    "    # apply gamma correction using the lookup table\n",
    "    return cv2.LUT(image, table)\n",
    "\n",
    "# construct the argument parse and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-i\", \"--image\", required=True,\n",
    "                help=\"path to input image\")\n",
    "args = vars(ap.parse_args())\n",
    "\n",
    "# load the original image\n",
    "original = cv2.imread(args[\"image\"])\n",
    "\"\"\"\n",
    "# loop over various values of gamma\n",
    "for gamma in np.arange(0.0, 3.5, 0.5):\n",
    "    # ignore when gamma is 1 (there will be no change to the image)\n",
    "    if gamma == 1:\n",
    "        continue\n",
    "\n",
    "    # apply gamma correction and show the images\n",
    "    gamma = gamma if gamma > 0 else 0.1\n",
    "    adjusted = adjust_gamma(original, gamma=gamma)\n",
    "    cv2.putText(adjusted, \"g={}\".format(gamma), (10, 30),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 3)\n",
    "    cv2.imshow(\"Images\", np.hstack([original, adjusted]))\n",
    "    \n",
    "    \"\"\"\n",
    "cv2.waitKey(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def adjust_gamma(image, gamma=1.0):\n",
    "\n",
    "    invGamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** invGamma) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "    return cv2.LUT(image, table)\n",
    "\n",
    "x = '/home/jorge/graygray/image18.tif'  #location of the image\n",
    "original = cv2.imread(x, 1)\n",
    "cv2.imshow('original',original)\n",
    "\n",
    "gamma = 1.5                                   # change the value here to get different result\n",
    "adjusted = adjust_gamma(original, gamma=gamma)\n",
    "cv2.putText(adjusted, \"g={}\".format(gamma), (10, 30),cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 3)\n",
    "cv2.imshow(\"gammam image 1\", adjusted)\n",
    "\n",
    "gamma = 2.0                                   # change the value here to get different result\n",
    "adjusted2 = adjust_gamma(original, gamma=gamma)\n",
    "cv2.putText(adjusted2, \"g={}\".format(gamma), (10, 30),cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 3)\n",
    "cv2.imshow(\"gammam image 2\", adjusted2)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture('/home/jorge/Documents/bRASIL/investigación/Videos e Sinais Douglas TG/MP4/5.mp4')\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    fgmask= fgbg.apply(frame)\n",
    "    \n",
    "    cv2.imshow('ori',frame)\n",
    "    cv2.imshow('filtro',fgmask)\n",
    "    \n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    #k = cv2.waitKey(0) & 0xFF \n",
    "    #if k == 27:\n",
    "     #   break\n",
    "    \n",
    "# When everything done, release the capture and destroy all windows\n",
    "# Cuando haya terminado, entregar el video y destruir todas las carpetas \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ultimo codigo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def adjust_gamma(image, gamma=1.0):\n",
    "\n",
    "    invGamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** invGamma) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "    return cv2.LUT(image, table)\n",
    "\n",
    "x = '/home/jorge/graygray/image18.tif'  #location of the image\n",
    "original = cv2.imread(x, 1)\n",
    "cv2.imshow('original',original)\n",
    "\n",
    "gamma = 1.5                                   # change the value here to get different result\n",
    "adjusted = adjust_gamma(original, gamma=gamma)\n",
    "cv2.putText(adjusted, \"g={}\".format(gamma), (10, 30),cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 3)\n",
    "cv2.imshow(\"gammam image 1\", adjusted)\n",
    "\n",
    "gamma = 2.0                                   # change the value here to get different result\n",
    "adjusted2 = adjust_gamma(original, gamma=gamma)\n",
    "cv2.putText(adjusted2, \"g={}\".format(gamma), (10, 30),cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 3)\n",
    "cv2.imshow(\"gammam image 2\", adjusted2)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
